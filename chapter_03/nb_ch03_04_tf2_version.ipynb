{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nb_ch03_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bXDt1QFarxhc"
      },
      "source": [
        "## Performing a single backpropagation step to updata the parameter values once\n",
        "\n",
        "**Goal:** In this notebook you will see how to use tensorflow to do a single update step based on stochastic gradient descent with one data point. You will do one forward pass and one backward pass and extract the gradients of intermediate terms in the computational graph. You use them for computing the gradients of the loss w.r.t. the parameters (slope and intercept) which are needed to do one updatestep.\n",
        "\n",
        "**Usage:** The idea of the notebook is that you try to understand the provided code by running it, checking the output and playing with it by slightly changing the code and rerunning it. \n",
        "\n",
        "**Dataset:** You work with a single datapoint of the systolic blood pressure and age data of 33 American women, which is generated in the upper part of the notebook . \n",
        "\n",
        "**Content:**\n",
        "\n",
        "* read book chapter 3.4.1 check how the provided code corresponds to the step by step computations in this chapter. \n",
        "\n",
        "* use the tensorflow library to set up the model \n",
        "    * define a computational graph containing all intermediate terms and local gradients \n",
        "    * do a single forward pass and compute all intermediate terms\n",
        "    * do a single backward pass and compute all local gradients and use them to compute the gradients of the loss w.r.t. the parameters via chain rule\n",
        "    * do a single update step of the parameter values\n",
        "    * verify that the computed values for the gradients and the updated parameter values correspond to the values in chapter 3.4.1.\n",
        "\n",
        "\n",
        "\n",
        "[open in colab](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_04.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-WLoi3XUyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c41154c-e9a9-43d7-eb3e-3ee756e1679a"
      },
      "source": [
        "try: #If running in colab \n",
        "    import google.colab\n",
        "    IN_COLAB = True \n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    IN_COLAB = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0TuJoV0XVXm",
        "colab_type": "code",
        "outputId": "3f0a3c20-d292-413e-c90e-9b85a2b7a532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "if (tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
        "    print('Please install tensorflow 1.x to run this notebook')\n",
        "print('Tensorflow version: ',tf.__version__, ' running in colab?: ', IN_COLAB)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please install tensorflow 1.x to run this notebook\n",
            "Tensorflow version:  2.1.0-rc1  running in colab?:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZkDvlnMjJxRe",
        "outputId": "4097bd4a-be43-47a2-8686-45fcc0ebacaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "import tensorflow as tf\n",
        "print('TF Version:', tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qIev26Cqa0VC"
      },
      "source": [
        "#### Blood Pressure data\n",
        "\n",
        "Here we read in the systolic blood pressure and the age of the 33 American women in our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zACb9J35KP92",
        "colab": {}
      },
      "source": [
        "# Blood Pressure data\n",
        "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
        "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
        "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
        "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
        "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
        "x = np.asarray(x, np.float32) \n",
        "y = np.asarray(y, np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4PVZDLZA0J3M"
      },
      "source": [
        "###  Doing the back propagation by hand for the example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GyWoQpLmjD_a"
      },
      "source": [
        "In the next cell we take only one woman of the dataset, because we want to calculate the gradients with only one datapoint. The woman is 58 years old and has a sbp value of 153."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uigQYLMs0B6s",
        "outputId": "0d64fd49-5890-4bbf-815b-9afae1de10cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = x[14]\n",
        "y = y[14]\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58.0\n",
            "153.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLnZCN2wjYlL"
      },
      "source": [
        "Here we define the computational graph with all the intermediate values and gradients in between, because we need them to apply the the chain rule and do the backpropagation. (see figure 3.12 in the book)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q8thmhCF0fq9",
        "colab": {}
      },
      "source": [
        "# Defining the graph (construction phase)\n",
        "\n",
        "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values, will be optimized later\n",
        "b_  = tf.Variable(139.0, name='b_var')                     # we name them so that they look nicer in the graph\n",
        "x_  = tf.constant(x, name='x_const')                       # Constants, these are fixed tensors holding the data values and cannot be changed by the optimization\n",
        "y_  = tf.constant(y, name='y_const')  \n",
        "\n",
        "\n",
        "# We now do it step by step so that we can calculate the intermediate values and gradients\n",
        "def my_func():\n",
        "  ax_ = a_* x_\n",
        "  abx_ = ax_ + b_\n",
        "  r_ = abx_ - y_\n",
        "  s_ = tf.square(r_)\n",
        "  mse_ = tf.reduce_mean(s_)                                 \n",
        "  return([a_,b_,x_,y_,ax_,abx_,r_,s_,mse_])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egd5fDz6GJPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_,b_,x_,y_,ax_,abx_,r_,s_,mse_=my_func()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jsNG3naRgPrU"
      },
      "source": [
        "#### Simple forward pass\n",
        "\n",
        "Now, let's do a simple forward pass and print the resulting values for ax, abx, r, s, and the mse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHUSw4n4AvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "abdd8e72-bd74-4813-9aa5-45e0dccf1fcd"
      },
      "source": [
        "vals = (ax_,abx_,r_,s_,mse_) # Letting the variables a=0 b=139 flow through the graph\n",
        "for p in vals:\n",
        "  print(p)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.0, shape=(), dtype=float32)\n",
            "tf.Tensor(139.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-14.0, shape=(), dtype=float32)\n",
            "tf.Tensor(196.0, shape=(), dtype=float32)\n",
            "tf.Tensor(196.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tjnLQHR5gder"
      },
      "source": [
        "#### Extracting the gradients and the updated values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eejBz7HSHlbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6ee661d2-58fc-4e20-d849-cd4cd76b4d99"
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.SGD(0.00002)\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  a_,b_,x_,y_,ax_,abx_,r_,s_,mse_=my_func()        \n",
        "  grad_mse_s = tape.gradient(mse_, s_)\n",
        "  grad_s_r = tape.gradient(s_, r_)\n",
        "  grad_r_abx_= tape.gradient(r_, abx_)\n",
        "  grad_abx_b = tape.gradient(abx_, b_)\n",
        "  grad_abx_ax = tape.gradient(abx_, ax_)\n",
        "  grad_ax_a = tape.gradient(ax_, a_)\n",
        "  gradients = tape.gradient(mse_, [a_,b_])\n",
        "  optimizer.apply_gradients(zip(gradients,[a_,b_]))  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "reQ0PK5rvNRN",
        "outputId": "63d10b1a-ab23-496a-91a3-fb4c351c30ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(grad_mse_s.numpy(),grad_s_r.numpy(),grad_r_abx_.numpy(),grad_abx_b.numpy(),grad_abx_ax.numpy(),grad_ax_a.numpy())\n",
        "print(a_.numpy(),b_.numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 -28.0 1.0 1.0 1.0 58.0\n",
            "0.032479998 139.00056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6H0Sl_CUqsE",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/ch03_12.pdf.png\" width=\"800\" align=\"left\" />  \n",
        "Compare the results of tensorflow with the results form the book where we did the forward and the backward pass by hand. The forward pass in blue and the backward pass in red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhRdf45yKCUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5667c872-de68-4f53-ab8d-9d1a2b455b65"
      },
      "source": [
        "\n",
        "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values, will be optimized later\n",
        "b_  = tf.Variable(139.0, name='b_var')                     # we name them so that they look nicer in the graph\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  a_,b_,x_,y_,ax_,abx_,r_,s_,mse_=my_func()        \n",
        "  grads_mse_a_b = tape.gradient(mse_, [a_,b_])\n",
        "print(grads_mse_a_b)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "[<tf.Tensor: shape=(), dtype=float32, numpy=-1624.0>, <tf.Tensor: shape=(), dtype=float32, numpy=-28.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-WWZE95oAvtD"
      },
      "source": [
        "#### Compute the gradient of the mse w.r.t to a via the chain rule "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tjLESXafnhQB",
        "outputId": "dd9269d0-d9d0-4a17-e965-ba87091b6dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#grad_mse_a \n",
        "print(grad_mse_s.numpy()*grad_s_r.numpy()*grad_r_abx_.numpy()*grad_abx_ax.numpy()*grad_ax_a.numpy())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1624.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AUuVUqLwmg8Q",
        "outputId": "68c03480-b7ee-4eb3-c974-120001a11395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#grad_mse_b \n",
        "print(grad_mse_s.numpy()*grad_s_r.numpy()*grad_r_abx_.numpy()*grad_abx_b.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-28.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Subdq2jOmYMp"
      },
      "source": [
        "#### Update Formula\n",
        "Verify that we get the same if we do the upate \"by hand\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGa4Z599kwjx",
        "outputId": "36eefe04-b2d8-4245-9f6e-2a2960243172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a0=0\n",
        "b0=139\n",
        "eta=0.00002\n",
        "print(a0-eta*grads_mse_a_b[0].numpy())\n",
        "print(b0-eta*grads_mse_a_b[1].numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03248\n",
            "139.00056\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}